# ğŸ¤– Rooman Support Assistant â€” AI Powered Support Agent  
### Built with OpenAI + Gemini + LangChain + ChromaDB + Streamlit


Deployed on Streamlit :  https://roomansupportinpy-2dx2nejxdvkttsmerdxrkx.streamlit.app/

 
The **Rooman Support Assistant** is a fully functional AI-powered support chatbot that uses:

- ğŸ”¹ **Keyword-based FAQ matching**  
- ğŸ”¹ **AI-based semantic search (RAG)**  
- ğŸ”¹ **Multi-model fallback (OpenAI â†’ Gemini)**  
- ğŸ”¹ **ChromaDB vector database**  
- ğŸ”¹ **LangChain embeddings**  
- ğŸ”¹ **Streamlit UI**  
- ğŸ”¹ **Rooman-styled branded interface**

It answers support questions automatically using FAQ documents + AI context understanding.

---

# ğŸš€ Features

### âœ… 1. Keyword Matching  
Fast rule-based matching using predefined FAQ keywords.

### âœ… 2. RAG (Retrieval Augmented Generation)  
If keywords fail, the system uses **semantic embeddings** + **ChromaDB** to find context.

### âœ… 3. Multi-Model AI Fallback  
Pipeline:

```
Keyword Match â†’ RAG Search â†’ OpenAI GPT-4o-mini â†’ Gemini-Pro â†’ Escalation
```

### âœ… 4. Upload New FAQs Anytime  
Through Streamlit sidebar.

### âœ… 5. Embeddings Rebuild Button  
Rebuild ChromaDB vector embeddings with single click.

### âœ… 6. Elegant Rooman UI  
- Sidebar with Rooman branding  
- Gradient headers  
- Chat bubbles  
- FAQ preview section  

### âœ… 7. Deployment-ready  
Works on **Streamlit Cloud**, **GitHub Codespaces**, **Local machine**, etc.

---

# ğŸ“ Project Structure

```
rooman-support-assistant/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ rag_engine.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ faqs.txt
â”‚
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ rooman_logo.jpeg
â”‚
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ chroma_db/            # auto-generated embeddings
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

# ğŸ§  Architecture Overview

```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚        User Input          â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Keyword Matching (Fast Lookup)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ No Match
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    RAG Engine (LangChain + Chroma)    â”‚
        â”‚ Semantic Vector Search on FAQs        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ No Context
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  AI Generation (OpenAI GPT-4o-mini)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ Error / No Output
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       Gemini-Pro Fallback Model       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
            Final Answer â†’ UI Display
```

---

# âš™ï¸ Installation (Local)

### 1ï¸âƒ£ Clone Repo
```
git clone https://github.com/YOUR_USERNAME/rooman-support-assistant.git
cd rooman-support-assistant
```

### 2ï¸âƒ£ Create Virtual Environment
#### Windows:
```
python -m venv venv
venv\Scripts\activate
```

#### Mac / Linux:
```
python3 -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies
```
pip install -r requirements.txt
```

### 4ï¸âƒ£ Add API Keys  
Create `.env` file:

```
OPENAI_API_KEY=sk-xxxx
GEMINI_API_KEY=AIzaSyxxxx
```

**Do NOT upload `.env` to GitHub!**

### 5ï¸âƒ£ Run App
```
streamlit run main.py
```

---

# â˜ï¸ Deployment (Streamlit Cloud)

### 1. Push project to GitHub  
Make sure `.env` is NOT uploaded.

### 2. Go to Streamlit Cloud  
https://share.streamlit.io

### 3. Create New App  
- Repo â†’ your GitHub repo  
- Branch â†’ main  
- File â†’ `main.py`

### 4. Add Secrets  
Go to **Settings â†’ Secrets** and add:

```
OPENAI_API_KEY="sk-xxxx"
GEMINI_API_KEY="AIzaSyxxxx"
```

### 5. Deploy  
Your app will be live at something like:

```
https://yourname-rooman-support.streamlit.app
```

---

# ğŸ§ª Testing the Chatbot

Try questions like:

- *"I want a refund" â†’ matches refund FAQ*  
- *"Change my password" â†’ matches password FAQ*  
- *"What are your working hours?"*  
- *"Contact support"*

If keyword fails â†’ it uses vector search  
If vector fails â†’ OpenAI  
If OpenAI fails â†’ Gemini  
If all fail â†’ escalates to support email  

---

# ğŸ”’ Why Two AI APIs Used?

We use **OpenAI + Gemini** for:

### 1ï¸âƒ£ Reliability  
If one model fails, the other replies.

### 2ï¸âƒ£ Better accuracy  
OpenAI GPT-4o-mini is excellent for support answers.  
Gemini-Pro is excellent fallback and cheaper.

### 3ï¸âƒ£ Safe enterprise architecture  
Multi-model fallback ensures **0% downtime**.

### 4ï¸âƒ£ Rooman interview advantage  
This shows:
- Multi-model routing  
- Fault-tolerant design  
- Real-world AI agent architecture  

---

# ğŸ˜ Author

**Developed by:**  
Rooman Technologies â€” AI Assistant Project  
V Veeresh

---


